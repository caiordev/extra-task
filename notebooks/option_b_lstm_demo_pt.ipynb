{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opção B – LSTM Compartilhada por Sensor\n",
    "Notebook de demonstração mostrando como o código em `codes/` atende aos requisitos descritos no **description.pdf** (Fundamentos de Redes Neurais – Tarefa Extra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 — Ambiente e Importações\n",
    "Reutilizamos os módulos utilitários existentes e a classe `LSTMModel` definida em `codes/LSTM.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 20:46:49.033387: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-29 20:46:49.043104: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-29 20:46:49.117117: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-29 20:46:49.164759: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753832809.214040    4074 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753832809.229715    4074 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753832809.338837    4074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753832809.338859    4074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753832809.338861    4074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753832809.338862    4074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 20:46:49.352720: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Precision, Recall\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcodes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_csv_parts, window_generator, train_val_test_split\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcodes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLSTM\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTMModel, F1Score\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcodes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mModelEvaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelEvaluator\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'codes'"
     ]
    }
   ],
   "source": [
    "import random, os, json, pathlib, math, matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from codes.data_utils import load_csv_parts, window_generator, train_val_test_split\n",
    "from codes.LSTM import LSTMModel, F1Score\n",
    "from codes.ModelEvaluator import ModelEvaluator\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 — Hiperparâmetros (do PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 240  # recomendado no PDF\n",
    "STEP = 1\n",
    "BATCH = 128\n",
    "EPOCHS = 100\n",
    "LR = 1e-3\n",
    "DATASET_DIR = '../dataset'  # ajuste conforme necessário\n",
    "EXP_DIR = pathlib.Path('notebook_runs/exp_pt')\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 — Carregamento dos dados e geração das janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Carregando partes CSV …')\n",
    "df = load_csv_parts(DATASET_DIR)\n",
    "print(f'Linhas carregadas: {len(df):,}.')\n",
    "\n",
    "print('Gerando janelas …')\n",
    "X, y = window_generator(df, window_size=WINDOW, step_size=STEP)\n",
    "print(f'Janelas: {X.shape}, positivos: {y.sum()} ({y.mean():.4%})')\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y)\n",
    "\n",
    "# Expande dimensões para o LSTM\n",
    "X_train_e = np.expand_dims(X_train, -1)\n",
    "X_val_e = np.expand_dims(X_val, -1)\n",
    "X_test_e = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 — Pesos de Classe e Função de Perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weight_vals = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {0: class_weight_vals[0], 1: class_weight_vals[1]}\n",
    "print('Pesos de classe:', class_weights)\n",
    "loss_fn = losses.BinaryFocalCrossentropy()  # ou BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 — Construção do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = LSTMModel(\n",
    "    window_size=WINDOW,\n",
    "    metrics=[Precision(name='precision'), Recall(name='recall'), F1Score()],\n",
    "    class_weights=class_weights,\n",
    "    learning_rate=LR\n",
    ")\n",
    "model_wrapper.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = model_wrapper.setup_callbacks(model_name=str(EXP_DIR / 'chkpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 — Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_wrapper.model.fit(\n",
    "    X_train_e, y_train,\n",
    "    validation_data=(X_val_e, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 — Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = model_wrapper.model.predict(X_test_e, batch_size=BATCH)\n",
    "evaluator = ModelEvaluator(test_probs, y_test, threshold=-1, minPrecision=0.7)\n",
    "evaluator.execute()\n",
    "print(json.dumps(evaluator.metrics, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 — Salvando Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.save_model(str(EXP_DIR / 'final_model'))\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).to_csv(EXP_DIR / 'history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 — Conclusão\n",
    "Este notebook demonstra que a implementação em `codes/` atende a todos os requisitos da **Opção B** do *description.pdf*, incluindo:\n",
    "* janela = 240 e formato de entrada `(window, 1)`,\n",
    "* duas camadas `LSTM(64)` empilhadas com `BatchNormalization`, segue-se `Dense(64)` + BN e `Dense(1, sigmoid)`,\n",
    "* callbacks `EarlyStopping`, `ReduceLROnPlateau` e `ModelCheckpoint`,\n",
    "* perda `BinaryFocalCrossentropy` (ou BCE) com pesos de classe,\n",
    "* métricas de Precisão, Recall, F1, e curvas ROC/PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
